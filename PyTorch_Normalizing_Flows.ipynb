{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.distributions as td\n",
    "import torch.distributions.transforms as t\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bijector for LeakyReLU\n",
    "class LeakyReLU(t.Transform):\n",
    "    \n",
    "    domain = td.constraints.real\n",
    "    codomain = td.constraints.real\n",
    "    bijective = True\n",
    "    \n",
    "    def __init__(self, alpha=0.5, validate_args=False, name=\"leaky_relu\"):\n",
    "        super().__init__(cache_size=0)\n",
    "        \n",
    "        self.alpha = nn.Parameter(torch.tensor([float(alpha)]), requires_grad=True)\n",
    "\n",
    "    def _call(self, x):\n",
    "        return torch.where(torch.greater_equal(x, 0), x, self.alpha * x)\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        return torch.where(torch.greater_equal(y, 0), y, 1. / self.alpha * y)\n",
    "\n",
    "    def log_abs_det_jacobian(self, y):\n",
    "        event_dims = y.dim()\n",
    "        I = torch.ones_like(y)\n",
    "        J_inv = torch.where(torch.greater_equal(y, 0), I, 1.0 / self.alpha * I)\n",
    "        # abs is actually redundant here, since this det Jacobian is > 0\n",
    "        log_abs_det_J_inv = torch.log(torch.abs(J_inv))\n",
    "        return torch.reduce_sum(log_abs_det_J_inv, axis=event_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 1\n",
    "\n",
    "def FlowLayer(n_layers):\n",
    "\n",
    "    flow = []   \n",
    "    for i in range(n_layers):\n",
    "             \n",
    "        flow.append(LeakyReLU(alpha=1))\n",
    "        flow.append(td.AffineTransform(loc=0.0, scale=1.0))\n",
    "    \n",
    "    return flow\n",
    "\n",
    "base_distribution = td.Normal(0, 1)\n",
    "logistic = td.TransformedDistribution(base_distribution, FlowLayer(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  8.,  17.,  58., 127., 211., 229., 200.,  93.,  46.,  11.]),\n",
       " array([-3.221581  , -2.625252  , -2.028923  , -1.432594  , -0.83626497,\n",
       "        -0.239936  ,  0.356393  ,  0.952722  ,  1.549051  ,  2.14538   ,\n",
       "         2.741709  ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(logistic.sample((1000,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000], requires_grad=True)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -tf.reduce_mean(dist.log_prob(x_samples))\n",
    "train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "NUM_STEPS = int(1e5)\n",
    "global_step = []\n",
    "np_losses = []\n",
    "for i in range(NUM_STEPS):\n",
    "    _, np_loss = sess.run([train_op, loss])\n",
    "    if i % 1000 == 0:\n",
    "        global_step.append(i)\n",
    "        np_losses.append(np_loss)\n",
    "    if i % int(1e4) == 0:\n",
    "        print(i, np_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DependentProperty()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
